{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Natural Language Processing for the creation (prediction) of Shakespeare poetry.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FTHLgJWIoUH"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20In%20Practice/Course%203%20-%20NLP/NLP%20Course%20-%20Week%203%20Exercise%20Answer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NPZeYZYvxwf"
      },
      "source": [
        "# Natural Language Processing for predicting shaekspear's poetry\n",
        "\n",
        "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. also add the basics like numpy, tensorflow, keras etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOwsuGQQY9OL"
      },
      "source": [
        "import json\n",
        "import tensorflow as tf\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.utils as ku \n",
        "import numpy as np \n",
        "\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"deep\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4nVGGRKwhjg"
      },
      "source": [
        "# Download the data \n",
        "with which we are going to work and save it in the tmp folder. Then create input sequences using list of tokens, [pad sequences](https://www.tensorflow.org/api_docs/python/tf/pad) and the creation of predictors and labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRnDnCW-Z7qv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68087c92-ef4a-4bcb-a865-772141f5d3f4"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt \\\n",
        "    -O /tmp/sonnets.txt\n",
        "data = open('/tmp/sonnets.txt').read()\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# create input sequences using list of tokens\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "label = ku.to_categorical(label, num_classes=total_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-14 16:22:06--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.63.128, 142.250.31.128, 142.250.73.240, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.63.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 93578 (91K) [text/plain]\n",
            "Saving to: ‘/tmp/sonnets.txt’\n",
            "\n",
            "\r/tmp/sonnets.txt      0%[                    ]       0  --.-KB/s               \r/tmp/sonnets.txt    100%[===================>]  91.38K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-06-14 16:22:06 (147 MB/s) - ‘/tmp/sonnets.txt’ saved [93578/93578]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13rAuGIMx85R"
      },
      "source": [
        "#Build the model \n",
        "\n",
        "This is a sequential model that uses regularizations such as **batch normalization**, **alphadrop**, and bidirectional LSTM of 150 and 100 and that we use `kernel_initializer = he_normal` and activation elu as well an optimizer like nadam with a `learning_rate = 3e-4` and we get the summary of the model with` model.summary () `.\n",
        "\n",
        "This was the model that gave me the best results of all those I tested.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9vH8Y59ajYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4fe3395-75e2-48af-c930-173cc3196a8e"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
        "model.add(keras.layers.AlphaDropout(rate=0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words/2, activation='elu', kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Nadam(learning_rate=3e-4)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer , metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "\n",
        "run_index = 1 # increment every time you train the model\n",
        "run_logdir = os.path.join(os.curdir, \"my_nlp4_logs\", \"run_elu_{:03d}\".format(run_index))\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "callbacks = [ tensorboard_cb]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 10, 100)           321100    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 10, 100)           400       \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 10, 300)           301200    \n",
            "_________________________________________________________________\n",
            "alpha_dropout_4 (AlphaDropou (None, 10, 300)           0         \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 100)               160400    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1605)              162105    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 3211)              5156866   \n",
            "=================================================================\n",
            "Total params: 6,102,071\n",
            "Trainable params: 6,101,871\n",
            "Non-trainable params: 200\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN63yb7X16_h"
      },
      "source": [
        "we run the model for 200 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIg2f1HBxqof",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e8ccc9f-ace4-4888-d8f6-c8444ffbb18c"
      },
      "source": [
        " history = model.fit(predictors, label, epochs=200, callbacks=callbacks, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "484/484 - 11s - loss: 22.9543 - accuracy: 0.0247\n",
            "Epoch 2/200\n",
            "484/484 - 6s - loss: 9.3949 - accuracy: 0.0281\n",
            "Epoch 3/200\n",
            "484/484 - 6s - loss: 6.7742 - accuracy: 0.0345\n",
            "Epoch 4/200\n",
            "484/484 - 6s - loss: 6.2614 - accuracy: 0.0436\n",
            "Epoch 5/200\n",
            "484/484 - 6s - loss: 6.0720 - accuracy: 0.0522\n",
            "Epoch 6/200\n",
            "484/484 - 6s - loss: 5.9080 - accuracy: 0.0644\n",
            "Epoch 7/200\n",
            "484/484 - 6s - loss: 5.7502 - accuracy: 0.0708\n",
            "Epoch 8/200\n",
            "484/484 - 6s - loss: 5.6028 - accuracy: 0.0791\n",
            "Epoch 9/200\n",
            "484/484 - 6s - loss: 5.4604 - accuracy: 0.0835\n",
            "Epoch 10/200\n",
            "484/484 - 6s - loss: 5.3370 - accuracy: 0.0920\n",
            "Epoch 11/200\n",
            "484/484 - 6s - loss: 5.2147 - accuracy: 0.0985\n",
            "Epoch 12/200\n",
            "484/484 - 6s - loss: 5.0952 - accuracy: 0.1065\n",
            "Epoch 13/200\n",
            "484/484 - 6s - loss: 4.9821 - accuracy: 0.1149\n",
            "Epoch 14/200\n",
            "484/484 - 6s - loss: 4.8783 - accuracy: 0.1216\n",
            "Epoch 15/200\n",
            "484/484 - 6s - loss: 4.7731 - accuracy: 0.1290\n",
            "Epoch 16/200\n",
            "484/484 - 6s - loss: 4.6780 - accuracy: 0.1317\n",
            "Epoch 17/200\n",
            "484/484 - 6s - loss: 4.5832 - accuracy: 0.1438\n",
            "Epoch 18/200\n",
            "484/484 - 6s - loss: 4.4947 - accuracy: 0.1513\n",
            "Epoch 19/200\n",
            "484/484 - 6s - loss: 4.4014 - accuracy: 0.1554\n",
            "Epoch 20/200\n",
            "484/484 - 6s - loss: 4.3196 - accuracy: 0.1679\n",
            "Epoch 21/200\n",
            "484/484 - 6s - loss: 4.2392 - accuracy: 0.1756\n",
            "Epoch 22/200\n",
            "484/484 - 6s - loss: 4.1536 - accuracy: 0.1848\n",
            "Epoch 23/200\n",
            "484/484 - 6s - loss: 4.0804 - accuracy: 0.1947\n",
            "Epoch 24/200\n",
            "484/484 - 6s - loss: 3.9913 - accuracy: 0.2077\n",
            "Epoch 25/200\n",
            "484/484 - 6s - loss: 3.9206 - accuracy: 0.2163\n",
            "Epoch 26/200\n",
            "484/484 - 6s - loss: 3.8384 - accuracy: 0.2288\n",
            "Epoch 27/200\n",
            "484/484 - 6s - loss: 3.7657 - accuracy: 0.2403\n",
            "Epoch 28/200\n",
            "484/484 - 6s - loss: 3.6841 - accuracy: 0.2555\n",
            "Epoch 29/200\n",
            "484/484 - 6s - loss: 3.6150 - accuracy: 0.2674\n",
            "Epoch 30/200\n",
            "484/484 - 6s - loss: 3.5429 - accuracy: 0.2801\n",
            "Epoch 31/200\n",
            "484/484 - 6s - loss: 3.4687 - accuracy: 0.2935\n",
            "Epoch 32/200\n",
            "484/484 - 6s - loss: 3.3990 - accuracy: 0.3062\n",
            "Epoch 33/200\n",
            "484/484 - 6s - loss: 3.3349 - accuracy: 0.3228\n",
            "Epoch 34/200\n",
            "484/484 - 6s - loss: 3.2759 - accuracy: 0.3328\n",
            "Epoch 35/200\n",
            "484/484 - 6s - loss: 3.2016 - accuracy: 0.3472\n",
            "Epoch 36/200\n",
            "484/484 - 6s - loss: 3.1365 - accuracy: 0.3635\n",
            "Epoch 37/200\n",
            "484/484 - 6s - loss: 3.0818 - accuracy: 0.3761\n",
            "Epoch 38/200\n",
            "484/484 - 6s - loss: 3.0272 - accuracy: 0.3890\n",
            "Epoch 39/200\n",
            "484/484 - 6s - loss: 2.9657 - accuracy: 0.4014\n",
            "Epoch 40/200\n",
            "484/484 - 6s - loss: 2.9050 - accuracy: 0.4208\n",
            "Epoch 41/200\n",
            "484/484 - 6s - loss: 2.8345 - accuracy: 0.4334\n",
            "Epoch 42/200\n",
            "484/484 - 6s - loss: 2.7834 - accuracy: 0.4424\n",
            "Epoch 43/200\n",
            "484/484 - 6s - loss: 2.7384 - accuracy: 0.4530\n",
            "Epoch 44/200\n",
            "484/484 - 6s - loss: 2.6914 - accuracy: 0.4614\n",
            "Epoch 45/200\n",
            "484/484 - 6s - loss: 2.6280 - accuracy: 0.4785\n",
            "Epoch 46/200\n",
            "484/484 - 6s - loss: 2.5892 - accuracy: 0.4885\n",
            "Epoch 47/200\n",
            "484/484 - 6s - loss: 2.5303 - accuracy: 0.4999\n",
            "Epoch 48/200\n",
            "484/484 - 6s - loss: 2.4963 - accuracy: 0.5071\n",
            "Epoch 49/200\n",
            "484/484 - 6s - loss: 2.4429 - accuracy: 0.5195\n",
            "Epoch 50/200\n",
            "484/484 - 6s - loss: 2.3824 - accuracy: 0.5349\n",
            "Epoch 51/200\n",
            "484/484 - 6s - loss: 2.3622 - accuracy: 0.5386\n",
            "Epoch 52/200\n",
            "484/484 - 6s - loss: 2.3061 - accuracy: 0.5526\n",
            "Epoch 53/200\n",
            "484/484 - 6s - loss: 2.2715 - accuracy: 0.5627\n",
            "Epoch 54/200\n",
            "484/484 - 6s - loss: 2.2382 - accuracy: 0.5633\n",
            "Epoch 55/200\n",
            "484/484 - 6s - loss: 2.1979 - accuracy: 0.5769\n",
            "Epoch 56/200\n",
            "484/484 - 6s - loss: 2.1599 - accuracy: 0.5838\n",
            "Epoch 57/200\n",
            "484/484 - 6s - loss: 2.1246 - accuracy: 0.5894\n",
            "Epoch 58/200\n",
            "484/484 - 6s - loss: 2.0838 - accuracy: 0.6044\n",
            "Epoch 59/200\n",
            "484/484 - 6s - loss: 2.0452 - accuracy: 0.6125\n",
            "Epoch 60/200\n",
            "484/484 - 6s - loss: 2.0085 - accuracy: 0.6147\n",
            "Epoch 61/200\n",
            "484/484 - 6s - loss: 1.9851 - accuracy: 0.6233\n",
            "Epoch 62/200\n",
            "484/484 - 6s - loss: 1.9438 - accuracy: 0.6321\n",
            "Epoch 63/200\n",
            "484/484 - 6s - loss: 1.9131 - accuracy: 0.6401\n",
            "Epoch 64/200\n",
            "484/484 - 6s - loss: 1.8974 - accuracy: 0.6392\n",
            "Epoch 65/200\n",
            "484/484 - 6s - loss: 1.8582 - accuracy: 0.6517\n",
            "Epoch 66/200\n",
            "484/484 - 6s - loss: 1.8233 - accuracy: 0.6544\n",
            "Epoch 67/200\n",
            "484/484 - 6s - loss: 1.8042 - accuracy: 0.6610\n",
            "Epoch 68/200\n",
            "484/484 - 6s - loss: 1.7816 - accuracy: 0.6656\n",
            "Epoch 69/200\n",
            "484/484 - 6s - loss: 1.7496 - accuracy: 0.6721\n",
            "Epoch 70/200\n",
            "484/484 - 6s - loss: 1.7313 - accuracy: 0.6771\n",
            "Epoch 71/200\n",
            "484/484 - 6s - loss: 1.7012 - accuracy: 0.6839\n",
            "Epoch 72/200\n",
            "484/484 - 6s - loss: 1.6831 - accuracy: 0.6868\n",
            "Epoch 73/200\n",
            "484/484 - 6s - loss: 1.6612 - accuracy: 0.6852\n",
            "Epoch 74/200\n",
            "484/484 - 6s - loss: 1.6313 - accuracy: 0.6980\n",
            "Epoch 75/200\n",
            "484/484 - 6s - loss: 1.6188 - accuracy: 0.7006\n",
            "Epoch 76/200\n",
            "484/484 - 6s - loss: 1.5868 - accuracy: 0.7073\n",
            "Epoch 77/200\n",
            "484/484 - 6s - loss: 1.5720 - accuracy: 0.7106\n",
            "Epoch 78/200\n",
            "484/484 - 6s - loss: 1.5501 - accuracy: 0.7136\n",
            "Epoch 79/200\n",
            "484/484 - 6s - loss: 1.5292 - accuracy: 0.7174\n",
            "Epoch 80/200\n",
            "484/484 - 6s - loss: 1.5186 - accuracy: 0.7201\n",
            "Epoch 81/200\n",
            "484/484 - 7s - loss: 1.4987 - accuracy: 0.7216\n",
            "Epoch 82/200\n",
            "484/484 - 6s - loss: 1.4723 - accuracy: 0.7304\n",
            "Epoch 83/200\n",
            "484/484 - 6s - loss: 1.4630 - accuracy: 0.7317\n",
            "Epoch 84/200\n",
            "484/484 - 6s - loss: 1.4457 - accuracy: 0.7361\n",
            "Epoch 85/200\n",
            "484/484 - 6s - loss: 1.4237 - accuracy: 0.7354\n",
            "Epoch 86/200\n",
            "484/484 - 6s - loss: 1.4122 - accuracy: 0.7451\n",
            "Epoch 87/200\n",
            "484/484 - 6s - loss: 1.4010 - accuracy: 0.7428\n",
            "Epoch 88/200\n",
            "484/484 - 6s - loss: 1.3812 - accuracy: 0.7488\n",
            "Epoch 89/200\n",
            "484/484 - 6s - loss: 1.3688 - accuracy: 0.7507\n",
            "Epoch 90/200\n",
            "484/484 - 6s - loss: 1.3510 - accuracy: 0.7548\n",
            "Epoch 91/200\n",
            "484/484 - 6s - loss: 1.3300 - accuracy: 0.7579\n",
            "Epoch 92/200\n",
            "484/484 - 6s - loss: 1.3249 - accuracy: 0.7586\n",
            "Epoch 93/200\n",
            "484/484 - 6s - loss: 1.3088 - accuracy: 0.7636\n",
            "Epoch 94/200\n",
            "484/484 - 6s - loss: 1.3109 - accuracy: 0.7580\n",
            "Epoch 95/200\n",
            "484/484 - 6s - loss: 1.2943 - accuracy: 0.7635\n",
            "Epoch 96/200\n",
            "484/484 - 6s - loss: 1.2739 - accuracy: 0.7697\n",
            "Epoch 97/200\n",
            "484/484 - 6s - loss: 1.2570 - accuracy: 0.7696\n",
            "Epoch 98/200\n",
            "484/484 - 6s - loss: 1.2684 - accuracy: 0.7679\n",
            "Epoch 99/200\n",
            "484/484 - 6s - loss: 1.2515 - accuracy: 0.7707\n",
            "Epoch 100/200\n",
            "484/484 - 6s - loss: 1.2364 - accuracy: 0.7753\n",
            "Epoch 101/200\n",
            "484/484 - 6s - loss: 1.2270 - accuracy: 0.7744\n",
            "Epoch 102/200\n",
            "484/484 - 6s - loss: 1.2102 - accuracy: 0.7782\n",
            "Epoch 103/200\n",
            "484/484 - 6s - loss: 1.2002 - accuracy: 0.7816\n",
            "Epoch 104/200\n",
            "484/484 - 6s - loss: 1.1777 - accuracy: 0.7901\n",
            "Epoch 105/200\n",
            "484/484 - 6s - loss: 1.1830 - accuracy: 0.7837\n",
            "Epoch 106/200\n",
            "484/484 - 6s - loss: 1.1680 - accuracy: 0.7880\n",
            "Epoch 107/200\n",
            "484/484 - 6s - loss: 1.1615 - accuracy: 0.7897\n",
            "Epoch 108/200\n",
            "484/484 - 6s - loss: 1.1556 - accuracy: 0.7895\n",
            "Epoch 109/200\n",
            "484/484 - 6s - loss: 1.1480 - accuracy: 0.7906\n",
            "Epoch 110/200\n",
            "484/484 - 6s - loss: 1.1649 - accuracy: 0.7823\n",
            "Epoch 111/200\n",
            "484/484 - 6s - loss: 1.1308 - accuracy: 0.7938\n",
            "Epoch 112/200\n",
            "484/484 - 6s - loss: 1.1219 - accuracy: 0.7940\n",
            "Epoch 113/200\n",
            "484/484 - 6s - loss: 1.1279 - accuracy: 0.7923\n",
            "Epoch 114/200\n",
            "484/484 - 6s - loss: 1.1167 - accuracy: 0.7966\n",
            "Epoch 115/200\n",
            "484/484 - 6s - loss: 1.1178 - accuracy: 0.7957\n",
            "Epoch 116/200\n",
            "484/484 - 6s - loss: 1.0947 - accuracy: 0.7992\n",
            "Epoch 117/200\n",
            "484/484 - 6s - loss: 1.0776 - accuracy: 0.8031\n",
            "Epoch 118/200\n",
            "484/484 - 6s - loss: 1.0733 - accuracy: 0.8026\n",
            "Epoch 119/200\n",
            "484/484 - 6s - loss: 1.0718 - accuracy: 0.8036\n",
            "Epoch 120/200\n",
            "484/484 - 6s - loss: 1.0682 - accuracy: 0.8016\n",
            "Epoch 121/200\n",
            "484/484 - 6s - loss: 1.0798 - accuracy: 0.8016\n",
            "Epoch 122/200\n",
            "484/484 - 6s - loss: 1.0667 - accuracy: 0.8031\n",
            "Epoch 123/200\n",
            "484/484 - 6s - loss: 1.0579 - accuracy: 0.8040\n",
            "Epoch 124/200\n",
            "484/484 - 6s - loss: 1.0531 - accuracy: 0.8063\n",
            "Epoch 125/200\n",
            "484/484 - 6s - loss: 1.0246 - accuracy: 0.8145\n",
            "Epoch 126/200\n",
            "484/484 - 6s - loss: 1.0442 - accuracy: 0.8073\n",
            "Epoch 127/200\n",
            "484/484 - 6s - loss: 1.0222 - accuracy: 0.8119\n",
            "Epoch 128/200\n",
            "484/484 - 6s - loss: 1.0247 - accuracy: 0.8088\n",
            "Epoch 129/200\n",
            "484/484 - 6s - loss: 1.0062 - accuracy: 0.8155\n",
            "Epoch 130/200\n",
            "484/484 - 6s - loss: 1.0191 - accuracy: 0.8101\n",
            "Epoch 131/200\n",
            "484/484 - 6s - loss: 1.0131 - accuracy: 0.8109\n",
            "Epoch 132/200\n",
            "484/484 - 6s - loss: 1.0057 - accuracy: 0.8130\n",
            "Epoch 133/200\n",
            "484/484 - 6s - loss: 1.0109 - accuracy: 0.8107\n",
            "Epoch 134/200\n",
            "484/484 - 6s - loss: 0.9948 - accuracy: 0.8147\n",
            "Epoch 135/200\n",
            "484/484 - 6s - loss: 1.0033 - accuracy: 0.8087\n",
            "Epoch 136/200\n",
            "484/484 - 6s - loss: 0.9871 - accuracy: 0.8163\n",
            "Epoch 137/200\n",
            "484/484 - 6s - loss: 0.9932 - accuracy: 0.8109\n",
            "Epoch 138/200\n",
            "484/484 - 6s - loss: 0.9841 - accuracy: 0.8152\n",
            "Epoch 139/200\n",
            "484/484 - 6s - loss: 0.9648 - accuracy: 0.8190\n",
            "Epoch 140/200\n",
            "484/484 - 6s - loss: 0.9606 - accuracy: 0.8209\n",
            "Epoch 141/200\n",
            "484/484 - 6s - loss: 0.9752 - accuracy: 0.8167\n",
            "Epoch 142/200\n",
            "484/484 - 6s - loss: 0.9651 - accuracy: 0.8168\n",
            "Epoch 143/200\n",
            "484/484 - 6s - loss: 0.9550 - accuracy: 0.8201\n",
            "Epoch 144/200\n",
            "484/484 - 6s - loss: 0.9436 - accuracy: 0.8217\n",
            "Epoch 145/200\n",
            "484/484 - 6s - loss: 0.9467 - accuracy: 0.8224\n",
            "Epoch 146/200\n",
            "484/484 - 6s - loss: 0.9645 - accuracy: 0.8161\n",
            "Epoch 147/200\n",
            "484/484 - 6s - loss: 0.9494 - accuracy: 0.8194\n",
            "Epoch 148/200\n",
            "484/484 - 6s - loss: 0.9373 - accuracy: 0.8203\n",
            "Epoch 149/200\n",
            "484/484 - 6s - loss: 0.9360 - accuracy: 0.8210\n",
            "Epoch 150/200\n",
            "484/484 - 6s - loss: 0.9232 - accuracy: 0.8257\n",
            "Epoch 151/200\n",
            "484/484 - 6s - loss: 0.9400 - accuracy: 0.8218\n",
            "Epoch 152/200\n",
            "484/484 - 6s - loss: 0.9259 - accuracy: 0.8249\n",
            "Epoch 153/200\n",
            "484/484 - 6s - loss: 0.9166 - accuracy: 0.8235\n",
            "Epoch 154/200\n",
            "484/484 - 6s - loss: 0.9192 - accuracy: 0.8247\n",
            "Epoch 155/200\n",
            "484/484 - 6s - loss: 0.9177 - accuracy: 0.8272\n",
            "Epoch 156/200\n",
            "484/484 - 6s - loss: 0.9126 - accuracy: 0.8247\n",
            "Epoch 157/200\n",
            "484/484 - 6s - loss: 0.9152 - accuracy: 0.8251\n",
            "Epoch 158/200\n",
            "484/484 - 6s - loss: 0.9222 - accuracy: 0.8218\n",
            "Epoch 159/200\n",
            "484/484 - 6s - loss: 0.9242 - accuracy: 0.8212\n",
            "Epoch 160/200\n",
            "484/484 - 6s - loss: 0.9054 - accuracy: 0.8232\n",
            "Epoch 161/200\n",
            "484/484 - 6s - loss: 0.8954 - accuracy: 0.8262\n",
            "Epoch 162/200\n",
            "484/484 - 6s - loss: 0.8944 - accuracy: 0.8271\n",
            "Epoch 163/200\n",
            "484/484 - 6s - loss: 0.8978 - accuracy: 0.8272\n",
            "Epoch 164/200\n",
            "484/484 - 6s - loss: 0.8947 - accuracy: 0.8274\n",
            "Epoch 165/200\n",
            "484/484 - 6s - loss: 0.8804 - accuracy: 0.8295\n",
            "Epoch 166/200\n",
            "484/484 - 6s - loss: 0.8873 - accuracy: 0.8278\n",
            "Epoch 167/200\n",
            "484/484 - 6s - loss: 0.8852 - accuracy: 0.8271\n",
            "Epoch 168/200\n",
            "484/484 - 6s - loss: 0.8914 - accuracy: 0.8259\n",
            "Epoch 169/200\n",
            "484/484 - 6s - loss: 0.8742 - accuracy: 0.8315\n",
            "Epoch 170/200\n",
            "484/484 - 6s - loss: 0.8727 - accuracy: 0.8313\n",
            "Epoch 171/200\n",
            "484/484 - 6s - loss: 0.8706 - accuracy: 0.8298\n",
            "Epoch 172/200\n",
            "484/484 - 6s - loss: 0.8711 - accuracy: 0.8309\n",
            "Epoch 173/200\n",
            "484/484 - 6s - loss: 0.8816 - accuracy: 0.8283\n",
            "Epoch 174/200\n",
            "484/484 - 6s - loss: 0.8714 - accuracy: 0.8276\n",
            "Epoch 175/200\n",
            "484/484 - 6s - loss: 0.8600 - accuracy: 0.8337\n",
            "Epoch 176/200\n",
            "484/484 - 6s - loss: 0.8592 - accuracy: 0.8333\n",
            "Epoch 177/200\n",
            "484/484 - 6s - loss: 0.8667 - accuracy: 0.8276\n",
            "Epoch 178/200\n",
            "484/484 - 6s - loss: 0.8597 - accuracy: 0.8322\n",
            "Epoch 179/200\n",
            "484/484 - 6s - loss: 0.8551 - accuracy: 0.8326\n",
            "Epoch 180/200\n",
            "484/484 - 6s - loss: 0.8590 - accuracy: 0.8302\n",
            "Epoch 181/200\n",
            "484/484 - 6s - loss: 0.8574 - accuracy: 0.8322\n",
            "Epoch 182/200\n",
            "484/484 - 6s - loss: 0.8517 - accuracy: 0.8338\n",
            "Epoch 183/200\n",
            "484/484 - 6s - loss: 0.8503 - accuracy: 0.8330\n",
            "Epoch 184/200\n",
            "484/484 - 6s - loss: 0.8400 - accuracy: 0.8340\n",
            "Epoch 185/200\n",
            "484/484 - 6s - loss: 0.8407 - accuracy: 0.8340\n",
            "Epoch 186/200\n",
            "484/484 - 6s - loss: 0.8409 - accuracy: 0.8343\n",
            "Epoch 187/200\n",
            "484/484 - 6s - loss: 0.8475 - accuracy: 0.8296\n",
            "Epoch 188/200\n",
            "484/484 - 6s - loss: 0.8436 - accuracy: 0.8329\n",
            "Epoch 189/200\n",
            "484/484 - 6s - loss: 0.8524 - accuracy: 0.8280\n",
            "Epoch 190/200\n",
            "484/484 - 6s - loss: 0.8348 - accuracy: 0.8320\n",
            "Epoch 191/200\n",
            "484/484 - 6s - loss: 0.8245 - accuracy: 0.8371\n",
            "Epoch 192/200\n",
            "484/484 - 6s - loss: 0.8241 - accuracy: 0.8368\n",
            "Epoch 193/200\n",
            "484/484 - 6s - loss: 0.8378 - accuracy: 0.8329\n",
            "Epoch 194/200\n",
            "484/484 - 6s - loss: 0.8396 - accuracy: 0.8323\n",
            "Epoch 195/200\n",
            "484/484 - 6s - loss: 0.8196 - accuracy: 0.8364\n",
            "Epoch 196/200\n",
            "484/484 - 6s - loss: 0.8213 - accuracy: 0.8360\n",
            "Epoch 197/200\n",
            "484/484 - 6s - loss: 0.8227 - accuracy: 0.8354\n",
            "Epoch 198/200\n",
            "484/484 - 6s - loss: 0.8227 - accuracy: 0.8370\n",
            "Epoch 199/200\n",
            "484/484 - 6s - loss: 0.8172 - accuracy: 0.8374\n",
            "Epoch 200/200\n",
            "484/484 - 6s - loss: 0.8291 - accuracy: 0.8316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nV-7oi062FgR"
      },
      "source": [
        "You get an accuracy of 83.16% and a loss: 0.8291. Then accuracy and loss is plotted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fXTEO3GJ282",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "eb618113-7bc6-492b-adc3-ba8f2abc0518"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NccUnsI31O2"
      },
      "source": [
        "it is obtained that accuracy increases and loss decreases, up to 75% then it increases very little until it stagnates in the eighties, and loss decreases all the way.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JFXVKCU8FWc"
      },
      "source": [
        "# Predict what poetry Shakespeare would write \n",
        "by giving him a sentence to complete the next 100 words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vc6PHgxa6Hm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "036a886f-2456-495d-c3f8-ae166428ab5a"
      },
      "source": [
        "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Help me Obi Wan Kenobi, you're my only hope sweet flattery each hate ears again dead lies here aside room remain rare to crave crave appear write back done me me done her forbear alone have thee lie so aside back again aside aside fits proved wide wind new care again up pace lie on thee it again gazeth up die so near slain ' grow back back back again lies untrue near slain decay 'no pace die her lie well well aside back again dead lies cherish wanting repair wife aside well used his lose old decay seeming dwell well ' grow used back back again rhyme lies\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgpWiLhh-g3r"
      },
      "source": [
        "gives us a good predictor but need more words to be more accurate but it is moderately decent"
      ]
    }
  ]
}